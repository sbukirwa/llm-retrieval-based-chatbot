SPEAKER 0
Today. So let's try to keep it productive. Today, we're going to be talking about modelling representation of language and more importantly, language models, which is a topic that is extremely important in this model. Right. Let's start with language modelling. I'm going to start with a very quick activity. Let's just say that you are building a voice assistant and the assistant is working and you heard something which it considers to be ambiguous. You heard potentially two sentences a sentence. Number one is I like feeding pigeons. This in this number two is I like feeling bludgeons. Which sentence do you think is the most likely? And more importantly, how do you measure it? So what I want you to do for the next 5 minutes is just pair with each other and then try to discuss how you would do it with your current state of knowledge. It may be a lot. It may be no law to just. Well, how do you think you could measure, which is the most likely sentence that was uttered? And I'm starting to counter now in 4 to 5 minutes and going start randomly pointing at people and asking questions. So, yes, I can do it after the lecture, but not right now because I'm lecturing. What do you think we're doing? And how do you measure? But the great start. You know, Googling the answer, are you?

SPEAKER 1
I through the. Partially because of the fact that just recently.

SPEAKER 0
I know. Yeah, I was just looking for. Isolation and isolation.

SPEAKER 1
I'm not doing that.

SPEAKER 0
All right. Does anybody have anything they would like to volunteer as a potential solution to this very difficult problem? Yeah. Do you have an answer? So it can be a bit louder than this one. Okay, but how do you measure that? Okay, But based on what I. So what you're saying is that you want to know which one is the most likely based on the possibility, the probability of seeing those words in the data, Right. Yeah. What is her condition in the word? Okay, this is not nice because you already found the answer. Yes.

UNKNOWN
You. Sentence one.

SPEAKER 2
The first one would be. Now, what was the shift on these once giving out visions? And then also in terms of the understanding, you know, when you look at this sentence, it's likely that. Yes. So that's why.

SPEAKER 0
Right. So you arrived at the same answer, which is basically conditioning the probability of observing the word pigeon based on the presence of the word feeding before that. So this. You're not.

SPEAKER 2
My responsibility. We are more prepared than.

UNKNOWN
You know how to get out of the.

SPEAKER 2
So we want you to know that.

SPEAKER 0
Grammatically speaking, those two things are equivalent. They're both nouns.

SPEAKER 2
Yeah, but, like, nothing concrete. But like many confidence state is another creation. You can only take it.

SPEAKER 0
Right? You can probably try to throw some bread at the bludgeon and see if it gets it grammatically. Those both sentences are extremely correct. And and yes, you can, as you said, like try to free the bedroom. So yes, you're correct that semantically, obviously one is more likely. I mean, unless the person speaking is crazy, one is a lot more likely than the other. And I think you edged on the right thing when you were talking about the probability of observing those words in the data. And in the end, this is really what we try to do with language modelling, right? So the problem of language modelling is that given a sequence of tokens here, single words we want to be able to predict which is the most likely next token to be we call a sample from the language. So for instance, here we're trying to measure the probability of ala fitting pigeons versus I like fitting bludgeons. I'm assuming most people here I've at least heard of, of like basic quality fury. I'm not going to go very deep into it. I don't even think we touch on base. So it's going to be very rudimentary. But basically, if you use like some basic definition of conditional probability, what it means is that we can calculate the probability of observing all those words simply by conditioning each word on whatever word is preceding it, which end up with something like this. Right. And that's all fine. So in this case, we have probability of high probability of life condition. I want to do a feeding condition. I like quality of pigeon condition and I like feeding. That's all fine. Right. So how do we find that probability? Well, it's very simple. We can just compute number of times we see. I like feeding pigeons. We divide it by the quality of I like feeding. And that gives us a good estimate of this thing here, this term, which is the only different term with the other sentence. Right. So the other sentence, we have the same three terms here because it's the same sort of sentence, but then you will just differ with that one. So we just measure this and then if you observe enough data, we do some counting, we have some probability obviously is going to be pigeons because, you know, the world still makes sense. So that's fine. But what if that sentence does not appear in that case? What we do is that we make some very strong, very naive, very wrong, but very useful assumptions. We assume the language is much, much simpler than it actually is. So here, instead of having the probability of the word, I conditioned to everything, what is the AI? What we do is that we actually condition it's only on a small window before the current word. So what we do is that we just restricted on this very restricted set of preceding words. We assume that language is a stochastic and sort of memory less process, and then we use that assumption to simplify our probability counting. So here, for instance, if so, we call that oh, I should I mentioned we call that the variable order Markov models. You don't need to know that that word is just a formal term for it. But the variable part basically is how deep we go into our memory. So if we go with the memory of one, then we conditioned everything only on the preceding state. So I like feeding, like pigeon feeding, which we also have with no memory at all, a pure Markov process. And then in that case we just multiply each probability of single word being observed together. And counting those, as you can expect, is a lot easier than counting specific sentences and hoping they appear. Because they don't appear. We're screwed, right? I mean, what would you end up doing? Zero. Which means it's impossible. So this is two more example here. So yeah, macro mode over there. Zero. Well, we have no contextual clue. This doesn't actually tell us whether the first sentence is more likely than the second one, because if it just happens that bludgeons appears more often than pigeons, then you know that probability is going to be higher for the wrong sentence than the correct one. Markov model of other one. On the other hand, conditions it on the previous term, which means that we have the kind of feeling. Pigeons versus feeding bludgeons here in our comparison. And that makes things work much more nicely because obviously, I really hope that this one will never appear in any sensible text. What we call this is a technical term, but we call this a maximal accurate estimate of of the probability. So for instance, if we were the sample from the Berkeley restaurant for the corpus that we're going to use in the lab tomorrow. So this corpus is a small sample of it. It's all about ordering food, which is very easy to understand. Oh, we end up with a probability like this looks sort of counts like this. So here we have word AI and then the word AI minus one, and then we count basically in that corpus every time. It is preceded by two 686 Chinese is preceded by eat 16 and so on and so forth. I'm assuming you get the point. Then we use that we can compute some nice probability and then we can have a very nice statistical language model. So just a follow up of the example here. So the uniform counts for the one that starting the sentence, as you can see, much more likely to have an isolated AI than having an isolated lunch usually don't really start the sentence with lunch. And then if we just use those uni grams to normalise our table of counts to end up with actual probability conditional probabilities, we end up with this thing. And you can see this sounds like a state machine where you can see if you are the state AI. Then the most likely following words is want or eat. This likely is all the zeros obviously and spend. And then the most likely word after once is to see the 6% for obvious reasons, just how grammar works and so on and so forth is any question about this so far? Yes, it does. It goes from left to right next to one, so. Oh, yeah. I didn't put the I didn't have the space to put the view, but this is the preceding word here and the word is I this I minus one. So I mean the probability of so if you have one then the most likely word after that is to Right. So if we just take this example, right, and we want to calculate the probability of I want English food, then we have the quality of I given. So this is the start of sentence talking and the end of sentence. And we just keep multiplying those probabilities together and they'll give us a nice number and that's it. We can estimate the probability of a sentence. So fine. Right. Or is it now 3 minutes much shorter? Because I'm not sure anybody. Mean, it may be obvious for some people, but can you figure out what is an obvious problem with this? And I'm going to start the counter now.

UNKNOWN
It's too bad. I remember. I remember last. Couple of. Yeah.

SPEAKER 1
Yeah. But still some. Indiscriminate cuts on the. I experimented last year. I would like to push this forward going crazy. And I spent about seven or eight of those looking for cover.

SPEAKER 0
To determine what.

SPEAKER 2
I don't say.

SPEAKER 0
They were. All right, all right, all right, all right. I want some answers, and I want them now.

SPEAKER
Well, yes.

SPEAKER 1
If you just look at the previous work it doesn't account for because it's the example if you see it yesterday and then the next 40 minutes, the next one. But it could be one day, right? If he said, okay, if the sentence is I want to insult anybody besides anything yesterday. It should be pointed instead of one. And if you just look at the previous one, which is I know a lot of them are not at all. For instance, you know.

SPEAKER 0
So this is very interesting. This is actually a much more advanced problem than the one I was referring to in that question. It's called a long term dependency problem. And this is why a lot of modern research in natural language processing focuses on a very deep neural networks. And all kind of fancy deep learning algorithm is to actually keep track of this kind of dependencies when generating language. So this is very correct, but it's not the one I'm referring to now. This is a much, much simpler one. Yes.

SPEAKER 1
I'm going to say.

SPEAKER 0
Too complicated and expensive. Uh, not really. I mean, it's. It's. It's fine. Is counting single words like you can do that almost instantly in the modern computer. It's a much more fundamental problem than this. Yes. You know, your first.

SPEAKER 1
So I suppose there might be something regarding saying that you have a response which doesn't match the idea that it might be. Oh.

SPEAKER 0
Right. Getting warmer. Yes, there was a Henry's was.

UNKNOWN
Convinced that it needed to be massive.

SPEAKER 0
Mm. That is a problem, but it's not the one I'm thinking about right now. You're on the right track when you say there's a new word. What do we do with it? Is there any race there? I saw some. No. Yes.

SPEAKER 1
What about.

SPEAKER 0
I think that's referring to the the other answer I heard about like long term dependencies of like trucking context is aloha is very hard. If you have only one word, but in theory, you could have multiple words if you wanted to. Yes. So. You look in my eyes? Yes, that is correct. So this is coming back to what you what you were saying about what if and you were the piers. And this is very correct. What happens if there is a word that just happens to not appear in your data set? Does that mean it's impossible? It's not impossible. You just means you haven't seen it yet. Right. So if we apply our language model in the new sentence, you just need one by gram, which is not appearing in the set and you just drag the entire probability of to zero. So you kind of annihilated like an entire subsection of possible output. And the way we deal with this in language modelling is that we try to redistribute some of the weights that we have, the probability mass that we have on some of the backgrounds that we know appear, and we try to redistribute that so that everything gets a piece right. So something would be extremely unlikely, but it's never really impossible. It's like fitting bludgeons, right? I mean, that's insane. But, you know, it's not impossible. So this is called the Cromwell principle, which is like can always assume that you know something, Nothing is completely impossible. You can always make a mistake. So right now, what we do is if you assign a property of zero to a background, which doesn't appear. But what if you're wrong? So in this case, what we do, it's called Laplace smoothing. So it applies to a mathematician. And what he did in probability is just basically very simple thing. Just add a little bit of weight to everything. So in this case, it was just one. So if you just add one to the numerator here, then that's it. Nothing is impossible anymore, except, of course, that it doesn't sum up to one which if you've taken any probability class, you know, the teacher will just slap you if you did that. So what we do is that we just balance things out. So if you have a vocabulary of, let's say V, right, we just add one to everything and we add to the numerator and denominator and that's it. Now our probability just balances out for a property. Nothing is impossible anymore. And we want of course, that's a very simplistic way of doing things. In real language modelling, we don't do things that simple. We have like mixtures of language models and things like that. However, this is this is the same general principle of redistributing weights from things that we have to things that we don't know, you know, might might occur in the future. There's a few popular like if you look up in the literature and I mean you will, but if you do, you will find names like Mercer within Bell. And these are these are maybe like the best performing one currently. And yeah, you don't need to know those into details. If you want to read the papers. Go ahead. But I'm going to quiz you on it. I might not even know in detail, so you might have to quiz me. Just know that they exist. And the general principle of kind of redistributing the weight. Now, the last question here is how do we know if it works? Right? We have a language model. Nice probabilities. Cool. How do we know if it works? We know that language. One else can be used to generate text. Right. There are probabilities. So I don't know if you ever. Have you ever use your phone keyboard and just press the centre of recommendation of words repeatedly to see what happens. This is how language model work, right? They they take a random word, right? And then they're just simple, which is the most likely word after that, and then wish the most every word after those words and so on and so forth until until you're bored. Really. Same principle here. What we do is that we use that principle to generate language, and we use that to measure whether the language which is generated is actually something we could observe in the real world. We go to the Shannon game once again during the into details. Just know that it and the general principle of how we evaluate language model. We know that a good language model should assign more probability to sentences that we actually see in a text. If our English model gave a higher probability to I like fitting Belgians and that does not appear in a text, that would be a terrible English model and we would throw it away. So we do this. We use a measure called perplexity, which is the inverse probability of the observation of the test at a set in order to compare those language models. In practice, you just call like, you know, I create perplexity in Python and then something does it for you. Don't worry about that bit. And we want the language model which minimises perplexity, which means that has the greatest chance of generating the dataset. So the first is the completion of the first part, which is how fast? Just in time. Language models are cool. I mean, I'm pretty sure convince you of that. We talked about uni grants last week. We can use language models to compare likelihood of documents, which may seem like a rubbish thing right now, but it's something you use all the time. Spell checking those that speech, understanding in your life, your phone or your Google home does that the words suggestion in a mobile keyboard does that. If you use Gmail, I don't know if you've noticed that you can write for you now you just type a button and then you just write part of the email for you, which is crazy. So all of this, they all use language modelling to some extent, it's used outside of language. So language modelling techniques are used, for instance, to generate molecules in, in biostatistics and all this kind of sub field kind of merging with machine learning. So it's a very kind of, you know, useful thing to know. Right. Part two. Any questions so far? Yes. So I usually upload them before the lecture, but I was editing those to make them shorter. By the way, just so you know, until like about half an hour ago. So I will put them on Moodle as soon as I'm done. Not right now, but literally 5 minutes after we finish this lecture, I promise. Any question about the thing, no less. So we'll explain. How could you. Oh, look at this. An activity. Right. Natural language generation. So I just want to have your opinion about something. What do you think are the two main objectives of a natural language generation system? So if you were to build a system that generate language, what are the two things you will need it to do? And free minutes kind of quiz people in 10 minutes. Starting now.

UNKNOWN
And. I. Whether.

SPEAKER 1
Oh, yeah. And that. What they found. You know, young men. We have so much resistance a us. I'm just gonna make it work. You know? It just got me thinking.

SPEAKER 0
Oh. I wish. John Hawkins.

SPEAKER 1
By the end of the.

SPEAKER 0
Was Baltimore. Yeah. It's one of the things in Baltimore. Any answers? Who wants to be daring? She wants to be daring. That's just. What do you have to say? Yeah.

SPEAKER 2
Okay.

UNKNOWN
So the first one tries to understand the first. The second one is to have the information from the. And also posted.

SPEAKER 0
Right. I hear a cure that we like here. Human. Understandable. So that one is good. The other one is not good. So you mean understandable? Yes. Another one? Yes.

SPEAKER 1
Right.

SPEAKER 0
Hmm. That is an objective. I wouldn't say it's the main one. You know, if you make a radical mistake still. Yeah. But it is. You're right. It is an objective. Yes. So it doesn't represent data. I think that goes way a little bit before the actual generic. So is really a generation step. Like you have data, you're generating language. What are the two things? Yes. You wanted to do. So can you read the. Continue with the meaning of words. It's once again. Also, this is one of the. It is correct, but it's not one of the main ones I think like. Yeah. This is this is more towards the understandable side of things. Yes. And to keep. Yes. Yes, that's right. So this is the second one. Right. So there's two things. The first one is it needs to be understandable and then it needs to meet a specific communicative goal, as in like, it needs to do something. And there's good reason for that. I'll talk about that a bit later. But yeah, the feel of natural language generation, usually we kind of define that as two main definitions for the the main researchers in the field. But this is one like my favourite one is to deliberately construct a natural language text in order to meet communicative goals. So this is the community side. And then here produce and this, and then will text in English or the human other human language. So there all the things he needs to do, right? He needs to be grammatically correct. He needs to be adapted in details to the specific like goal. There's there's a lot of the things, but the two main ones are these ones. There are many schools of thought in how you would do natural language generation. I've classified that into two. It does as many classifications as there are people researching the field, so you might not see the same one if you look at it like a textbook, but usually you will have template based ones which are a bit more fixed, more rigid, and then the dynamic ones which use like basically start from nothing and just generate text in a dump based one. You have things called gut feelings in systems. So gut feeling would be, you know, you have like a string of characters and then gaps inside and then insert the name of the customer there and then insert the dates of whatever, and then you just fill those gaps and then send an email and that's it. That's natural language generation. It's very simple, right? But it works and it meets. It needs the criteria is understandable. You can make it fit a specific communicative goal. You know, if you write the email correctly and and usually it has very low error rate because, I mean, you know, you cannot make any mistakes. You just needs to have to fill the gaps. Then you have a bit more complex rule based systems. The kind of like gap fitting systems are a bit more expendable. So you have specific rules that kind of extend or reduce, let's say, the message based on some criteria that you define. So we'll be more flexible. So very low error rate as well, but obviously not very novel. Then you have I'm not going to go into detail on this, but grammatical functions are complex templating systems. So I don't know if anybody here has done a like ultimatum fairy and like visual languages and things like that. But this is in the same kind of family of approaches. Very boring. One. Go into detail. I generation cooler. This is the kind of stuff you have in your Google home or whatever. And basically they use very big neural networks and then generate text and and yeah, that's just really it's a very high novelty. So you can make your phone say whatever you want, but because of that, sometimes you get stuff wrong. That's the price we have to pay. So yeah, as I said, I categorised two into the two big categories template based, more fixed you, more inputs from you dynamic, more data driven, but obviously makes more errors because well, unless and until we create true artificial intelligence, there's always going to make a lot of mistakes and it will happen. You know, you get what you want from that. Right. So I mentioned before, natural language processing is understanding plus generation. So understanding usually comes from taking text and then feeling like data from the text. So we create a computerised kind of knowledge from natural text generation is the other way around. We take this thing and we want to generate a text from it. A text like this, for instance, Paris or something, something or whatever, which are called 14 degrees and little fender storms. So that could be generated by completing system and and LG needs to make a little decision to arrive at something like this. So, for instance, here, as you can see, it's used the same date in the sentence for both the temperature of London and Paris. So here we have the same date and then you kind of merge those two sentences into one. Here it makes a qualitative assessment. So determining that 14 degrees is cold. So it says it will reach a cold, 14 degrees and not a boiling 14 degrees. Then you talk about trend of storms and then contrast that with London, which should be rainy and even colder. So it kind of detects a. Change in temperature and then qualifies that in the text, not going over 12 degrees. So as you did not write this, I did. So it because you wondering but I did that based on what I know energy system do. And he does quite a few things. So those are some of the main tasks that this system goes through. So it starts with a communicative goal and then go through something called document planner and the micro planner and a real laser and then apply outward some text. I think I don't really like this, even though that's the one that's mostly used in textbooks. I think this is much easier to understand. There's many stages in template B's and LG. The first one content determination, which is basically what what is the output we want to communicate? What should we put in a text? That depends, as I said, on the communicative goal, but also it depends on the level of precision, right? If you generate a text for doctors and the text for laypeople, those are both going to have different kind of vocabulary and different level of details. It also depends on the surprise of the information. So if you are building a system for nurses, for instance, and then you want to generate this patient has cancer, you want to make sure that this point is clearly understandable and clearly obvious from the text. You don't want to hide that in a long paragraph. So this kind of things are important when determining the kind of content that we want. Second thing is structuring. So now we have all this information that we took from atoms, and then we will know in what order that we put it and how to group it all. Do we talk about once again if we do a weather reports? Do we talk about country by country, city by city? Do we just go through alphabetical order? Basically, like how do you structure that information? Then goes the lexical choice. So here the second choice is what are the actual words that you use to express what you want? Once again, that depends on the public who is going to consume that that text? It depends on many things, depends on genre. You will use the same words in a weather report as in the novel, for instance, on the context. So if you're generating words, for instance, which needs to be read by someone driving a car, you're not going to generate Shakespeare because you know, it needs to be like five words max on the side of the dashboard and many other things. Then a bit more detailed. So referring expression generation refers to the creation of expressions that make explicit references to entities that were mentioned somewhere else in the text. So a very simple example here pronounced is a simple one the simplest one. If I say pull into the cafe, he was hungry. Well, in that case, you know, he is referring to pole. And for the machine to output a text like this. It need to understand that you can use he as a shortcut as a referring expression for pole in for the text. This is a simple one, but they are a lot more complex way of having referring expressions the columns aggregations. I show an example of this in the example just before. If I say Paris is warm and is warm, then I can aggregate those syntactic groups as if Paris and London all warm, or I can do conceptual aggregation. If I say something, they will be cold and they will be cold. Therefore, the weekend will be cold and just output. The weekend will be cold because it's much easier to understand and it sounds more natural. But this is actually a complex step because it means that the machine needs to understand that Saturday plus Sunday equals the weekend. So a lot of application rules and things like that need to appear here. Finally, the realisation step, which is more the details, the polishing on the output. So here you have syntactic visualisation, you know in what order that you put the words morphology, corporatisation, plural, singular orthographic validation like capitalisation, punctuation and all kinds of small details here. Okay. So that was done based on the dynamic natural language generation. Not more fun, no more free thoughts kind of thing. So I mentioned this before. Probably language models can be used to generate text. The way you do it basically is that you have a context, which is your current sentence, which can be empty or like in process you have a communication goal that you find a way to encode. And then what you do is just keep sampling new words and then conditioning them on your context, which is the sentence as it is right now and your goal. And you just keep sampling until you have simple the end of sentence token and then you stop there. This is a terrible, terrible way of doing like purposeful kind of an LG, so I would not recommend it. However, you can generate very entertaining things as you probably tried with your phone by just kicking the middle button and see the kind of nonsensical stuff that comes out of it. I mentioned this very briefly. I'm not going to go into much detail, but your networks are the current kind of modern way of doing natural language generation. You've used them, whether you know it or not in your phone, you've used them in Google or whatever search engine. You use what they do. And I think I'll mention long term dependencies before I do that as an example, is that they can generate much better text because they can keep track of context from sentence to sentence and even from paragraph to paragraph. So they can generate something which is a lot more useful or at least more coherent. However, it's very hard to encode a specific goal out of it, which is why if you're doing something like generating emails, usually you still stick to a template based methods and logic and how many uses we're finishing soon, Don't worry. I think I mentioned a few before. Informational. So weather reports, medical summaries, financial reports, and the kind of stuff that like an MLG engineer would end up working on. Entertainment does a lot of research on story generation, though fun of a role playing these kind of things is also used for interaction. So text interfaces for websites can sometimes use NLG to kind of replace the clicking and whatever that we usually do also use for assistive technologies. So I think I mentioned before as well, it's quite common now to have some bots which kind of just describe scenes for you if you have visual issues. It's also used for journalism, unfortunately, and those very annoying chat bots. I'm just pointing fingers here. Example of those, you know, that just pop up randomly when you're browsing the web. And yeah, so all of the examples that that analogy can be used in practice and concrete this. So I hope I convey the main point, which is an LG goes from a spectrum with like very strict low error and very free, high error, more creative kind of energy systems. Most energy system in the wild and of being the kind of boring but safe kind just because, you know, if you're generating financial report, you want to make sure the point is is coming across but you also have some like more free energy systems that do things like movie script writing and things like that. No real reading for you except those bits. This is a short movie that was written by an AI. It's complete nonsense, but it's very fun to see. Then you can play with a text generator here very like a deep neural network kind of one. And you can see this thing, which is. Wait, wait. 1 minutes. Come on, you can make it. I know you can. You can play with this. Which is someone train bots to kind of emulate communities on Reddit and then let them wild in one specific community where you can see them interacting with each other in surprising sometimes ways. And perhaps not this. Right. That's it. Any questions? Right you gave.
