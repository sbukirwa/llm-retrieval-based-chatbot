SPEAKER 0
Electron won't connect to my Mac, so I'm going to have to improvise between using the slides as PowerPoint and the audio from my Mac. Hopefully that will be okay. So today's lecture is going to be kind of a deep dive into the topic of progressivity, which I touched on previously with regards to voice interface design. And this is actually a paper we published three, four years ago now on three years ago at the Conversational User Interface Conference. And it's about progressivity. So first of all, what is progressivity? It's actually a concept from conversation analysis and it concerns the progress of talk and interaction. And this is the paper that we are using quite heavily in this paper and our paper as a kind of a template. And the starting point for Stevenson, Robinson's paper from 2006, Heritage, one of the founders of conversation analysis called Progressivity, a great principle of conversational organisation. So this is human human conversation we're talking about and this is the concern of conversation analysis. So that's where progressivity comes from, comes from human human talk and the study of conversation analysis. So here's an example. Here's an example of a conversation that's used by Davis and Robinson in that paper, which is a conversation between mom and boy. Why? Mom said, Mom says, What are you doing, Dad? Well, Dad is at the phone. And then it's actually the boy that looks at the dad and the dad is leaning over the phone and the boy answers. He is listening. Okay. So why is this Why am I showing you this? Well. Well, you know what happens actually, quite a lot in human conversation is that not the person who's being addressed to give the answer? So the selected speaker gives the answer, but somebody else gives the It gives an answer. It gives a response on their behalf, if you want. And so that shows us that within conversation there's a preference for an answer over a preference of a response by the selected next speaker. So it's more important for there to be an answer by someone who is party to the conversation than for that person that is selected that, you know, is selected to give the next two to be the next speaker. This conversation, analysis sort of lingo and the selected speaker. So it's more important for for an answer to be forthcoming than for that answer to be specifically from the selected next speaker. Okay. A bit more about progressivity. It also relates to the what's called the trouble problem conversation. So Sugarloaf already in the late seventies, we talked about progressivity. It was again, you know, obviously in the context of human conversation, is that amongst the most pervasively relevant features in the organisation of talk and other conduct in interaction, is the relationship of adjacency or nexus moving from some element to a terribly next one with nothing intervening. It's the embodiment of and the measure of progressivity. Okay. So he I outlined this phrase with nothing intervening. So I think this is important when it comes to thinking about progressivity. There isn't anything intervening that blocks us that keeps us from moving on in the conversation. He also talks about the trouble, the trouble problem, which is where he says how to deal with trouble in speaking, hearing and or understanding the talks so that the interaction does not freeze in place when trouble arises. Into subjectivity is maintained or restored, and that the tone and sequence and activity can progress to positive possible completion. Again, I and Circle will try to do a PowerPoint. I think it's I did it in the right way. So corrected for me. So does not freeze in the right place or just so it does not freeze in place. Again, this is important to think about the and the converse here, which is, you know, what causes the trouble in conversations. I've got some notes here. Sorry. And what causes the trouble in conversations? Is when there's something that freezes in place and also that can then in turn and, you know, the goal here that's being outlined is to the progression of progress to possible completion. So that is another way of thinking about progressivity. So if progressivity is hindered, then the goal of progressing to completion is hindered and therefore that's the trouble problem in conversations. And we then have to try and fix, try and repair the problem to be able to move on to possible completion. Okay, So moving on. So in summary, halting progress is to be avoided. And progression to completion is the goal in a conversation. But of course as well, the same applies to interactions with voice interfaces. Here are some of the central principles. Or these are the central principles that Stevens and Romans and their paper outlines. First off, answers are preferred to non answer responses. And we'll get to see some examples of what that means in the context of applying it to voice user interface interactions. Secondly, non answer responses in progress. So if a response is for forthcoming, but that response is not really an answer to what was requested, then that can be that can actually impede progress too. So the sequence certainly accounts offered can lead to recovery. We'll see examples of what that might mean. Accounts in this case means something like an explanation for what went wrong. Fourth, participants work to receive answers. We've seen this in the context of the family trying to get the voice interface to work, but you see this in conversations with multiple in multi-party conversations as well, where you have multiple people talking and trying, you know, basically trying to progress the conversation and make sure that answers are forthcoming. So moving on can be more important than receiving an answer. This is another thing that's important for voice interfaces as well. Yeah, at the end of the day, this shows us as well that just progressing to towards completion, whatever that means in a conversation, is more important than giving the correct answer. So we apply this framework to examine progressivity in voice user interface interaction. And of course, you know this work already. This builds on the same corpus of data that we collected when Martin gave an Amazon echo to five households. And each of these had the Amazon Echo for one month. And they also had the conditional voice recorder that Martin built and basis of the Raspberry Pi, which listens to the same wake word that the Alexa listens to. It records one minute before and one minute after it hears the wake word. And that's what allows us to obtain a reference corpus of and family interactions or, you know, household interactions, let's say, with the Amazon Alexa. So and I'm going to go and show and play some more of that audio to you. And what I'm also what I'm going to do is I'm going to adopt this three part will be called a three part based sequence. By industry mean interactions. So that's the person. And here is Alexa. So you have these three part based sequences of exchanges between the interact and the person talking to Alexa, Alexa and and then a 33rd turn by the interact and we call those terms question or command turn. This is where of course the person first addresses the Alexa in a kind of request turn. Then we get the response from Alexa. And then this is the key thing here for what we're going to be looking at is what the interaction does after that response from Alexa. Because that was that will show us something about how that interaction unfolded. I mean, of course, as observers, we can make our own assumptions about whether we think that was successful or not. But really, it's about the situation. And in the situation, it's the person themselves responding to the response. And thus we can use that analytically as an evaluation turn. So let's look at some examples from our data. So I'm going to play the audio from the MacBook.

SPEAKER 1
Can't play at all. I have all of them on the house. Some guns on Texas. Oh, on the show tonight?

SPEAKER 0
Yeah. Don't worry. I'm not going to play all of that. So. Yeah. So what happens here? It's pretty straightforward. Rob asks Alexa to play all of em, and which is a radio station in the UK, and Alexa then responds after a pause. All left Amman, Jordan, and then plays the radio. Okay, so we've got first turn the if you go back to what we've seen, this three part basically was a question of command. So and the response and then the evaluation. So here we've got the question turn Alexa, play all of them and then we have the response, Turn all off. I'm on June and then playing the radio. Now we do not have an evaluation turn for this in itself is an evaluation. There's an absence of anything else that because there isn't anything left to do, Rob remains silent, right? He does not need to and he does not need to do anything else because what he wanted to accomplish was achieved. Nothing left to do, given that the desired outcome is which is the radio's playing has occurred. Okay, so this is in itself in the interactive interaction with voice interfaces. So the evaluation tone being silent, being absent is in itself an evaluation for that interaction to be possibly successful. Now let's look at a different example where which you've already you've already heard this, But let's think about this again. There's always something else you can spot with these things. So this is the family.

UNKNOWN
Alexa sent us a family quiz. Sorry, I can't.

SPEAKER 1
Find the answer.

UNKNOWN
To the question I had. Alexa, set a family quiz.

SPEAKER 1
Sorry, I don't have the answer to my question.

SPEAKER 0
Okay. So I've broken down the longest sequence that you've heard before and the previous lecture into this one. This is, of course, again, the family of the family that we've had. Or they're trying to open a family quiz, go on to using the kind of the wrong keyword. Now, the point here is that we we can we can define Alexa's answer on Alexa's response as a non-answer response. Right. So why is it a non answer response? Because. Well, it's not an answer to the question that was that was posed it or the commands. Right. So it doesn't it doesn't relate to and it is not an answer to the request or question that was posed. And so and so you can see this is impeding progress. Why can you see that? Well, because it leads to repetition with Emma rephrasing slightly, but this using the same keywords again and again. Another non-answer response follows on from that. So you can see how this is impeding progress through the sequence. And so let's take a look at how this continues.

SPEAKER 1
Alexa, set up a quiz. I wasn't able to understand.

UNKNOWN
The question I have. She's like, Sir, family quiz.

SPEAKER 0
Okay. So you can see that it continues to be the progress continues to be impeded by nonsense responses. But also what this shows is that you have the family as a whole. Now, what really kind of working together to receive an answer from Alexa. So when you can see that throughout the whole sequence that I've played now, every family member tried to get the desired response from Alexa, and all of them have failed. But you can see they're collaborating and they are, you know, taking turns. They are rephrasing each other's requests and slightly different ways. And obviously they're having fun at the same time as well. That's always important. So this one now. A few examples that go back to going back to Rob. And let's have let's have a listen to this one more time.

SPEAKER 1
And to start white noise. Sorry, I'm having trouble understanding. I like to start white noise. Welcome to White noise.

SPEAKER 0
Okay, Well, listen to that again.

SPEAKER 1
As in me. So I'm going to start white noise. Sorry, I'm having trouble understanding time. So start White noise. Welcome to White noise.

SPEAKER 0
Okay, so I think this goes a bit better here because because we're actually seeing well, you're actually seeing a successful outcome in the end. You have a question I just wanted to ask what you didn't understand or is it like I said? Well, the numbers and just the numbers are just like numbers. So I can refer to the line number if I want to.

SPEAKER 1
X is going next transcription or human reason.

SPEAKER 0
It is human. It is not. An Alexa transcription is. It's a transcription we've we've created and sorry about the misalignment here does look not quite right to us because that's because this is a PowerPoint the keynote presentation open on PowerPoint as well. It looks a bit weird. Yeah. Because of the numbers in the. Okay. Sorry. So these numbers always line numbers. These numbers are are pauses in seconds. Okay. So if it's just a dog like that, that's 2.2 second paws. You can count them like this. So one tick is like a point to a second pause. So, um. Yeah. And then, I mean, this is. This is going into the orthographic notations of transcriptions. This is an elongation. So start. See what it says. Yeah.

SPEAKER 1
But how do you complete this process?

UNKNOWN
Like you like when you're listening to audio, Like just the timestamps?

SPEAKER 0
Yeah, it's an inexact science. I mean, you can try and be more exact, but. But yeah, you can count. And like I said, like when you listen to it, you can count them. And you know, quite often people, people do these short pauses in the middle, like in the middle of a sentence as well as quite natural. Um, this in double parenthesis is any other currencies you wish to know about the interaction that is relevant in this case? It's a beep sound that Alexa makes, but often it's also things like pointing or when you it's a way to be able to to add nonverbal nonverbal events into your transcript. Yeah, I was just wondering if the problem in this case is in the context of this process that takes property as a place.

UNKNOWN
Processes. You can imagine.

SPEAKER 0
Yeah. So I think that's a very good question. And I think that the part of the problem is that we don't know whether Alexa does not make that available, what the actual problem is. Is it because there's an error or is it because there's a network error? Or is it because there's a semantic error? So this is the intent. The keyword does not match an intent. So that's part part of the problem that people have when they interact with it, that they very rarely get given those resources to be able to move on, which which is kind of the case here in this example. So why why am I saying this is an account? Well, it is an account by Alexa for not being able to understand. It's just saying I'm having trouble understanding. I mean, of course know. In other words, you could say, well, it's not really it's not really an intelligent response. It's just one of those generic responses. But it doesn't matter in this case, because we look at the evaluation term, which is robust next term, which is actually a reformulation of the previous request. And what what is the actually doing is he's he's changing his pronunciation. You can hear that. You can hear that if I play that again.

SPEAKER 1
Alexa. He set for me, which I wasn't able to understand the question. I have highlights.

SPEAKER 0
Okay. Sorry.

SPEAKER 1
Time and then start white noise. Sorry, I'm having trouble understanding. I like to start white noise.

SPEAKER 0
You can see how he changes his pronunciation.

SPEAKER 1
To white noise.

SPEAKER 0
And and that leads to successful triggering of the correct. And so you can. You can. The point here is that we can treat Alexa's response as an account for the for the not understanding, which enables Rob to reformulate his request, which leads to successful outcome. Okay. So let's look at another example. Back to the family. And this time they're trying to open a game called Beat the Intro. Again, you've heard this before. But again, this is in in the context of progressivity. And you might this might give you some different ideas.

UNKNOWN
For. Okay, maybe the intro you want to hear is.

SPEAKER 1
Station four be the.

UNKNOWN
Intro, right? No, I'm going to let you know. All right.

SPEAKER 0
Right. So this is we've heard this before, but now that you're thinking about progressivity, you can see how this goes quite differently. And, you know, in some ways is successful because what we have is we have Alexa doing something we haven't really seen before, which is it produces this clarification question. You want to hear a station for B intro, right? That's the clarification. QUESTION So what does this do? This does two things. First of all, it proposes that Anna wants to hear a station, right? You want to hear a station, right? And the other other thing it does it doesn't only just do that, but it also adds in the speech to text transcription. Be the intro, right. It adds adds that into the into the clarification question, which is a transcription error of course, because we've heard she said beat the intro, but the transcription is baby intro. We actually I mean maybe that's a bit difficult to hear when you just hear it, but we actually verified this looking at the transcript on the device as well. So this is what Alexa transcribed or this is the, the transcription that it selected, Right. Selected to produce in the answer. So this gives Emma an immediate response or the ability to respond immediately. No. Right. No, I don't. Alexa. No. And Alexa then can respond to that. All right. So we can see the again, if you think about the evaluation tone here. So the three part response, the three part sequence, I must turn here. The evaluation turn very clear. No. All right. So it's very clearly a negative and a negative response. And yet it actually allows the progression of the sequence towards completion for some kind of completion, even though it's not the intended outcome, but is still in terms of progressing through a sequence that's still successful. Okay. And you can see how in the context of Stephen's and Robinson's framework, it does a lot of these other things as well, like it provides an account you want here station for being the intro, right? So this is the same as what we had before, where the response provides some sort of account which allows moving through the sequence, but also it also shows how the interactions are working to provide an answer or how well actually, I suppose this relates to Alexa as well. So the response Alexa gives to the clarification question is actually, do you mean this is actually working to provide an answer as working towards that kind of successful completion? No, I don't mean that. Okay, fine. We can we can all move on and get on with our lives. So progressivity is more important than providing an answer. And this is the same for this kind of situation where you've got a device. So let's let's listen to this final one.

UNKNOWN
Beeps at the entrance. That's it. Oh.

SPEAKER 0
So knows how. What I'm trying to highlight here is, is that at the end of the day, it's more important that there's something happening in the interaction. Even if it's. Even if that's not the response from the device. In this case, it's actually Emma that brings this to a close by saying, no, she didn't like that. Right. So we have this this principle, which is similar kind of we think it demonstrates a similar kind of principle that we have in humans during conversation where it's more important that some some answer in the context of a multiparty conversation is happening rather than in the answer from the selected speaker in this case, Alexa. So it's more important. It's this this will move the conversation on and it progresses regardless of the fact that Alexa did not respond. So you might say, oh, this is a failure. Yes, But, you know, as human beings, we can still move on and make light of it. Okay. So onto the discussion then. What does this all mean for us when we're thinking about progressivity? So, first of all, of course, you know, progressivity is situation of what do I mean by that? Well, it means that what counts as progress in a sequence emerges in the moment of the of the interaction in the context of its production. So you can't really use it to produce well-defined guidelines, like design guidelines, for instance. So it allows us to analyse a situation after it has occurred in this way, as we have done. But clearly, with all the things that occur in the in actual real world situations, it's kind of impossible to predict all of the nuances and all of the ways in which this can unfold. But so what can we say to designers? Because designers, of course, need to somewhat in some way be able to predict how an interaction might unfold so that you can design for the interaction. So taking that our three part by sequence, again, we can take this in two different ways. We can first use this to evaluate voice interfaces by focusing on what we can learn by analysing the interactions terms. Okay, so essentially what I've just done, right, so I've gone through a number of examples and in a way that is an evaluation off of the voice interface. Right. And I've, I've gone through and I've shown how focusing on what people say to it and what the responses and the evaluation turn this in and of itself is an evaluation of the voice interface. Secondly, we can also thinking about how we can use that knowledge to design for progressivity. What do I mean by that? So that we can focus on what we can or should sensibly do with the devices response? So what I've talked about before as response design. Because this is really what we can design, right? We this is in our it's in our gift to be able to say, you know, if if the request is this, then the response should be that that's that's what we do fundamentally when we build a voice user interface or chatbot. So we talk about this in a little bit more detail and focusing on the evaluation term. There are some things in that evaluation turn that tells us that there is trouble in the interaction. This includes things like gaps and pauses. So we of course, this is available to us as designers because as designers or as developers of voice interface, we can count the seconds since, you know, since the device produced the response. So if there's a long pause that is indicative of trouble, we hesitations or a similar kind of thing. But these can also be accompanied by verbal markers like. Right. So these are common in conversations between human beings. These are called hesitation markers. And we for all of these and then there's negative responses, as we've seen. So something like, No, I don't. And then there's overlapping talk. So if the user barges in decides to to over talk over the device, we can detect that. Again, that is usually a sign of trouble or signs. Her probably stopped producing output. And we can actually use a saw or an LP and computational techniques to detect all of these features. And current devices do not do that. Right. I mean, this is this is like what modern devices should be doing, but what they don't. So I'll focus a little bit on on the this table here from conversation analysis. We know a lot about different features within within conversation and what they do in terms of functions they have in terms of the conversation. So, for instance, we've got the we've been focussed on the initial question and command turn. This allows us to to do things like understand, address and initiation. Of course this in Alexa is done. So the key word, the wake word, Alexa. But within human conversation, this is typically accompanied by gaze. So by looking at someone. So if I say Jeremy and then I look at him and he looks back at me, then I know we are initiating an exchange. So we know this from we know this from conversation analysis and that we can use this to project the next speaker. I've just done that by looking at him and saying his name and he is expecting to be called upon to speak next. So and as I say in the in the context of Alexa interactions, of course, you know, you've got the wake word, but which is kind of a crude mechanism to address it. You could also have you can also have different mechanisms. There are, you know, within robotics, computer vision is used to see whether you are looking at the robot before, you know, as a as a form of address instead of saying the name. Right. So a different way of thinking about how you can address or initiate the interaction we have, then we have this kind of what we call a what they call within turn progressivity. So you have things like hesitations that I mentioned. Like so if you ask me something and I go, you know, I'm hesitating probably because I am unsure about what the responses, you know, and but there also backchannels like, huh? So if you are talking at me or I'm talking at you mostly and I see you nodding, that's a good sign because I think, yeah, you're understanding what I'm saying. So that's a kind of a backchannel. Now, these are also things that we could potentially detect computationally. Why not? Of course, you know, you might you might want to be able to incorporate camera cameras and so on so that you. Cohen, which has problems with surveillance. Of course, these things always, always have pros and cons, but there is this thing called incremental dialogue processing, which which is is the cutting edge of how as should be done in the opinion of those who do this research. Incremental dialogue processing is as would be a complete paradigm shift to how voice interfaces currently work. Because currently, as you all know, you say Alexa and then it just listens until you stop speaking and then it will take everything that was recorded then and then it'll transcribe that. And that's not how conversations work. Conversations, voice calls, correct, says back channels. There's all these things, hesitations, that allow you to then rephrase. Right. So the way you might be able to to approximate that kind of national conversation with, with a computational device is through an incremental dialogue processing where you are processing, you know, incrementally as time progresses and you are evaluating that. What I am saying incrementally question.

SPEAKER 1
Like voice.

SPEAKER
Voice is not, you know, talking to Google like if

SPEAKER 1
I. If I'm saying something, you should like what I'm saying. But you like each word based on the facts of.

SPEAKER 0
What I'm saying. Yeah, that's a good example. I think of of a bit of an approximation of that of of thought of incremental dialogue processing. So maybe it is going in that direction commercially now, but like Syria and Alexa I know are still not doing that for instance. So yeah, maybe there is I think dictation when you use dictation is a good example of of where they might, you know, where because dictation obviously is you can't you are just speaking said without a pause. So if they they are progressing what's being said and sending it to the answer kind of incrementally. Yeah but with what you mean with incremental dialogue scenes, things like of course correcting along the way as you are when you say, oh, I mean and then something else and then it actually picking that up and interpreting that as a self-correction. And I think that's the kind of stuff that is more a rare and more cutting edge, but hopefully is also finding its way into commercial products. And just finally, if we focus on the evaluation term, which obviously comes in response to the response, it allows us to understand something about post churn, progressivity. So, you know, this could this could for instance, this could, for instance, show that there is a lack of understanding. There was a long gap, right? Or there's overlapping talk which might indicate something like disagreement. So if I over talk the the devices response, probably I'm not happy with it. You know, you can you can take that bargain as a sign that there is something that is not going well with the interaction and about the end of this. Now, just without going into this, we can also, as I said, if you focus on the response and focus on the response design, we can think about how does the response help the user to get things done in the interaction. And we've kind of written down five questions in the paper. We're going into much more detail in the paper. And but this allows you, if you try to answer these questions as a designer, this response, could it be delivered minimally so that the user is allowed to progress to the next move earlier? So instead of having a really long response by the device, could it be shorter? Does this response support or impede the user to be sure of the voice understanding of the, you know, the previous request? Could other resources for providing the user move help move on with, you know, give them something to move on to? For instance, an account of what actually went wrong? Could it could the user provide more information to this response than expected as a result on how how would they be able to do that? And how do users themselves work to support and halt the progress of sequence in response to the VOI as well as more that more detail of it in the paper if you're interested in that. But just in conclusion, progressivity is a central concept in conversation analysis, and we also show how it's key in interactions with voice. And I showed some examples of that and showed how character characteristic features of trouble such as gaps, hesitations, negative responses and overlaps also present in that. And then I discussed how you can use that to evaluate progressivity and how you can think about things like response design as well. Okay. So that concludes the lecture today. Thanks very much and I will see you all on Thursday.
