SPEAKER 0
Having some technical issues. Okay, so this is quite a small lecture theatre, but there are some seats here. So if you are looking for a seat, there are definitely some seats available. You just have to squeeze in. All right. So I'm Professor Joel Fisher, and I brought along for your entertainment Dr. Jeremy Kloss as well, who will be helping me teach some of the modules, some of the lectures, and is an expert in natural language programming, which is very much what we need as part of the module. So welcome to human Interaction. Um, so who am I? I'm, uh, as I said, Joel Fisher from Minster Germany. You can call me Joel. That's fine. Uh, I came to do a PhD. Never left. So here I am. So what do I do? What do I teach? What do I research? Well, this is exactly my area of research. So I research human and human interaction, although I can't say it very well. That's quite a mouthful. Um, so my area is human computer interaction. So I'm interested in human robot interaction, robotics, interacting, interacting with robots, and particularly voice interfaces. And the kind of research we do often draws from social research methods to understand interaction issues, societal issues, that kind of thing. Um, so there are still some seats available here in the middle. You just have to come and kind of squeeze in. Um, so, um, I'm also part of a very large national UK right funded research hub for the trustworthy autonomous systems. And so you might hear us make reference to that. Um. So we're going to try and get a bigger room. But obviously for today, we're stuck with this one. The problem is and yeah, we don't know yet whether we can get a bigger room or not, but clearly it's it's not big enough for everyone. But there are still some seats available here if you want to come down and squeeze it in four in the front, three, four rows as well.

SPEAKER 1
Because if on the stairs there's nothing in those two figures today.

SPEAKER 0
So yeah, you can sit on the stairs. Apologies. We don't have any influence on what rooms we got. Timetabling.

SPEAKER 1
Legacies, whether we're.

UNKNOWN
Teaching, you know, years ago was the only way for you.

SPEAKER 0
Okay, So a few seats in the second row. Excellent. So, so good to see so many of you. I'm sorry about this morning. So what do I do when I don't work? I like to go climbing. I like to go running and hang out with our cats. Of course. Obligatory picture of cats and the first model slides. And. Yeah. So, Jeremy, do you want to come in?

SPEAKER 1
So I do have a lot of you from your first year. You might or might not remember me from when I was teaching the labs in programming. I'm from France that you might hear from my accent, and most of my teaching and my research is in natural language processing and various techniques for the mitigation of misinformation and propaganda. As for what to do when it don't work. Trick question. I'm never not working. So that's mostly my, my, my occupations.

SPEAKER 0
And that's a good approach.

SPEAKER 1
To both my hometown. Most beautiful city in the world, I guess. And I think that's about it, really.

SPEAKER 0
Welcome. You know, thanks to you and me, we couldn't do it without you. And so in this lecture, I'm going to try and give a bit of a motivation regarding what and why we need human interaction, what is why should be studied and what's needed. And I'm going to primarily do that by talking about examples of problematic. I am some more, I'm all problems. And then we're going to get to some practical stuff about the module work focus of the module and what the aims of the module for you and what you have to do to pass it and how we organise the module in lectures and labs, what the assessments are and well, you know the timetable already because you found this, which is great. And just highlighting some of those then as well at the end. Okay, so let's get straight into it so we can probably all agree that really is everywhere now in the kind of more obvious form factors like in Anthropomorphise robots. And we also have a kind of a part of manufacturing where people might use collaborative robots like this. And we see it everywhere in transportation, planes, trains, automobiles and great film. By the way. Autopilots are clearly more and more part positive of the world of transport, let's say. And autonomous vehicles, of course, are sort of the forums for end of the spectrum. But we see it more and more in kind of fairly mundane ways in the kind of vehicles you see, you see on the roads a lot nowadays, of course, as well. We also have robot robots in the home, either for domestic chores like vacuum vacuum cleaning, hoovering, if you want, but also these kinds of entertainment or personal assistant devices, which I'm sure many of you have, who's got an Alexa or Google home at home. Maybe a few more than last year. For some reason, they're not that popular with computer science students. We'll get to the bottom of that, I'm sure. Um, also in shopping, we see these food ordering systems. I mean, you know, when you order your Deliveroo and so on, there's definitely somebody on that. But but probably more obviously in these kind of more sort of automated delivery robots, which you have milk cakes for instance, you can order when you order from a supermarket, um, your groceries will be delivered, delivered in a robot. And that's all well and good, isn't it? That's great. And, um, that's exactly the kind of thing we're excited about with A.I.. But there are also a lot of problems with A.I., and so let's go over some of those. So in 2018, the Tesla autopilot was blamed for a fatal crash, if you remember that. So what happened was that the autopilot computer vision system failed to distinguish what was a grey lorry or truck turning from the, uh, the vehicle and um, was it was unable the vision system was unable to distinguish the colour of the truck from the colour of the sky. And so what happened was that the autopilot just drove straight into the, into the truck and the driver was also thought to have had his hands off the steering wheel at the moment of the collision. And this actually led to a redesign of the autopilot. So now in a Tesla autopilot, you always have to have your maintain your hands on the steering wheel. I think that's a nice example of human interaction. Right. So sometimes, you know, you don't you don't want to be able to over trust. This is this topic of over trust. And um, the trust are you don't want to over trust the A.I., you want to build something into the design of it so that you are, for instance, forced to maintain that level of control over it as a kind of security or safety feature. Other kinds of problems we have with AI in the UK. The UK councils have only just started to abandon the use of algorithms to make decisions about the benefits, benefits and welfare. These were found to be biased and they were found to select transparency and public scrutiny as well. Perhaps you might remember this. So in the UK the government used an algorithm to assess pupils A-level A-level results. So university entry exams. And this was down. This was done in a bid to avoid grade inflation. And actually nearly 40% of teachers grades were downgraded by the algorithm. Now, this is interesting because many of you have said, yes, so many of you actually got your A-levels two years ago. So who was affected by the A-level algorithm today? So that's interesting that some of you actually experienced this firsthand. So interesting to hear from you as well. So what happened was that this became known as the A-level fiasco, and it affected hundreds of thousands of young people and actually resulted in large scale public protests. And in the end, the government was forced to U-turn again. They never took another U-turn this morning anyway. And in the end, the teachers grades were reinstated and actually a few. I think it's quite remarkable that for the first time probably in the history of this country, you had people demonstrating, protesting, holding up signs, being pissed off about an algorithm. Okay. So I think this is quite, quite a remarkable time, really, if you think about it, the history of the country. We couldn't do it without the Home Office. In August 2020, the Home Office actually dropped it, dropped an algorithm for making these decisions, which was found to be racist, because what it did was it essentially categorised people from certain countries based on a traffic light system of green, amber and red. So just because you were from a certain country, we were more likely to have this kind of very crude categorisation attached to you and possibly have your visa denied. So you might say, is all of this really what's this really got to do with it? It's not really the point. I think the point I'm trying to make is isn't about the technology is often used as a in kind of in in in vernacular talk. Speech is used as a collection term for a range of computational techniques. Right. And we and you learn you're learning a lot of these while you're learning machine learning for for for sure expert systems, recommender systems and so on are kind of older types of A.I. systems. That's not the point, really. What the technology is that's underlying it. What's important is what they have in common is that they're used to drive decision making. And the common denominator of all of these examples is where that kind of decision making, driven by a computer driven by an algorithm, has gone wrong. And the point isn't what the technique is. The point is what we can make, what's going wrong, understanding what's going wrong with it, and how to avoid and improve it in the future. So some more problems with AI. This is an example of a facial recognition gone wrong. So this this gentleman here, Robert Williams, was arrested because of a faulty facial recognition system and an algorithm had wrongly matched his and his image from a CCTV and image from a CCTV camera of a shoplifter and matched that wrongly to his identity. He was jailed overnight and there was he had obviously a range of kind of legal complications as a result of that. And what we see with systems like that is that there can be systematic bias due to a lack of diversity in the training data. And this is often also referred to as racist bias in the system. And the Detroit Police Department. So using this technology even after this incident, because if you go back a little bit further, some of you might remember you remember remember this Microsoft case chatbot. Maybe not to see him few years ago now. So Microsoft released this chapter on Twitter and it started spouting racist tweets in less than 24 hours because it was the way it was programmed is that it started to adopt the language people were using to talk to it. And clearly, that's a very bad idea as as this example shirt showed. And so it only lasted about 24 hours, not even that. And it had to be taken down and lessons had to be learned from that. We'll talk more about what kind of lessons were learned from that as part of this module as well. So human interaction is key to all of these problems, as well as to kind of, I think, the good sides of these systems as well. So machine learning systems learn from human interaction. Right. There are datasets or training data that's underlying these systems, which are based on human interaction all around human interaction, such as transactions online. So things like where we click on a website, what we buy and so on. Of course, all that information is being used and harnessed by these systems, but then also natural language, and that's going to be a key part of what we talk about in this module, what we type into Google, what we, you know, say on social media. All of that can be used and harnessed as data to drive this kind of automated systems as well. Spoken language is actually, you know, distinction is, you know, language that we that we speak. So so speech obviously contains a lot more than a lot more information than text or written natural language. So it's distinction. So things like how we say things play into that and can can also be harnessed by systems. Facial recognition, how we look at facial features and so on can be and is being harnessed by systems. And then behavioural behavioural data, things like how we drive. And you could imagine that insurance companies are very interested in that kind of data where we walk and so on to, to try and improve things for us as well. So important thing to consider is AI systems that are built by people, people like yourselves, they are engineered by humans. So we have control over how we build them, for what purpose and so on. So we are responsible. And particularly as computer scientists, you are responsible and have a role to play in how these systems are built. So that's really in our hands and that's why I think it's important to think about things like what you know, what people are being part of the building efforts of these systems. Does that reflect how real people talk, look and what they do and so on? And are we just designing with an ideal, ideal kind of usage situation in mind, or have we considered all the cases as well, all the things that can go wrong? And clearly these systems down, just technical systems, they are, as we say, socio technical systems. They have a real impact on people and the environment in which they go. And it's important to think about how they're employed, used and misused as well and for what purposes. So. And I think once these systems are made to make decisions about other human beings, that's when it can it can get really tricky. And how these decisions affect peoples informed to think through. And they don't tend to just affect the uses of the system. Think about the example of Robert Julian Williams. You know, he wasn't a user of the system. He was recognised by some technology. And because of that, you know, he was wrongly jailed. So, you know, that's part and parcel of building these systems. We need to think about the ethical implications of the decisions that you're asking the A.I. to make. There's also another area that's interesting, which is thinking about the fairness with regards to the A.I. workers. You know, there's lots of there are basically now kind of call centres created all around the world where people create training, data, label images and so on, sort of sweatshops of A.I. and maintenance of these systems. Are they treated fairly? I think that's also another thing to think about. It's an ecosystem of, of, of things that we we need to think about when it comes to these kinds of systems. So to understand them, we kind of need to adopt different perspectives. We need to understand them from a technological point of view. That's that's what you're trained to do. That's your kind of primary primary arena. But now you are in year three. You are actually we're going to challenge you to think beyond the technical and also think about the social, think about the interactions such as how the input data drives behaviour over time and what, you know, the interactions might do to affect the outcomes of the system. So we we need to understand them socially, which also means we need to think about who has access to these systems and who doesn't, who might be excluded from the use of these systems and why. I'm like I said, those who don't use it might be affected as well. So thinking through, how does it impact on people's lives and so on is important and developing this kind of understanding, this is what this model is all about. So we need to take on different perspectives to do that, different disciplinary perspectives to do that. Okay. So getting on to. The scope of the module in terms of what you'll be learning. So as I mentioned, different perspectives are needed to build systems that are beneficial to people. So we'll be doing that. We'll be taking on different views, technological interactions, social and ethical views. So it's not just about designing and building interactive ballet. Take social view on these systems as well. Thinking about the people that build it, that run it, the people that use it and misuse it, and the people that might be affected by it. So that means taking on different disciplinary views. We can take on a social. We can take software engineering, computer science for you to understand how we can build better systems, create better datasets and so on. We can take on a design view or a human computer interaction with you, and we can ask how do we design better systems with people in mind? And different people that are affected by these systems as well. We can take on a view considering ethics and privacy and think through how we make sure that these systems are ethical, that they safeguard privacy, personal data. So. We can take on the perspective of responsible research and innovation, that that means we can we can start to think through what potential issues are we actually benefits from the innovations and who might be adversely affected. We can think about the equality, diversity and inclusion of the systems and infrastructures that we're designing and how do we ensure that groups of different people aren't excluded or treated unfairly or discriminated against by the systems that we built? So what about the audience? This is a level three module. So that means many of you are either in year three or four for the PSC or MCI. So who was a year three year four student?

SPEAKER 1
Okay.

SPEAKER 0
Okay. And then who's in and who's an MSI student? Master's student. Okay, so about 5050. Okay. So a word for embassy students. Right. Welcome. You're very welcome. However, programming is is a requirement. So you need a kind of working knowledge of concepts like object orientation, programming, data types, text processing. We're going to be working with list comprehension in python and understanding of algorithms and user input handling and so on. So it's a range of, you know, the range of of key concepts in programming that you need to be familiar with. And we don't require you to have worked with Python before because Python is a language that you can you can pick up, we think quite easily and quickly if you have been programming in other languages that are object oriented and. Yes. So I'm sure if you'll have some questions, we'll get into those at the end as well. So what are the aims of the module? We focus on two connected areas of H.R. systems. We can obviously focus on all of them that I talked about in the introduction. We focus on natural language processing or NLP, and we focus on voice user interfaces connected to that and voice, as I like to just say for short. And we'll do that in two ways. So you develop a kind of understanding of energy from the ground up and by by getting involved in practical programming of energy systems and you'll be implementing a basic but fully functional I know pieces to a chatbot, right? But you'll be you'll be actually designing it from the ground up, not using all those frameworks that are out there to make that really simple task. And you'll also learn the practical design of forces interfaces. So you'll be able to design, prototype and test a voice user interface. And to do to do that you'll be learning conversational design techniques and. As a kind of background to this, you'll be learning about conceptual basis of and linguistics. So you need to have a bit of an understanding of the structure of language, linguistics. And then also we'll be continuing to learn about multidisciplinary research that is looking at not just the technological, but also the social interaction and ethical challenges with regard particularly to natural language processing and voice user interfaces. Okay. I think this is you to talk a little bit more about this.

SPEAKER 1
Yeah. So ask a few details about it and help decide, because I'm the one who's going to be handling it. We're going to be focusing. I don't have many lectures with you, so we're going to focus on a few key concepts of categorising, text processing, text, writing, Bayesian inputs and evaluating NLP systems using Python. As you mentioned, if you don't have a background in Python, that is fine. I also want to clarify what working knowledge means. You don't need to be an expert in any of the topics that you've mentioned before, like object orientation, text processing and things like that. You're going to be picking that up as you go. But what you do is need to understand basic concepts of it can teach you as you go, but can't make you in a program if you have not before. As far as tools, we're going to be using three main things analogy K Natural language talk. It's very standard, kind of like academic ish kind of kind of tool. We're going to using Psychic Learn, which is a very basic and a basic like standard machine learning toolkit. And I'm going to be using numpy and sci fi, which has of libraries for numerical and scientific processing. They're fairly standard. So this kind of knowledge will be useful down the line. But yeah, I think that's about it, right? Oh, yeah. There is a textbook called your analogy. A textbook reference here. Feel free to go and have a look at it if you want to have some idea of the kind of things we're going to be talking about. But otherwise, we have a lecture on first day, right, where I'll go in more details on what I'm planning to do with you. Oh, I'm going to be using the A52 lab machines or the virtual desktop. So when we ask you to submit something like the coursework or whatever, it needs to be working on any of those things that are equivalent. So if it works, an effort to issue work on the virtual desktop and vice versa. And the reason why I'm saying this is because, you know, that's the only way I can ensure that I can run your program and market correctly, which I'm assuming is something you want. Everything all the software should be already installed. Oh, I'll go into more details if we talk about other packages and things like that. And. And yeah, I think. Yeah, I think this one.

SPEAKER 0
Yeah. Thanks, Jeremy. So then, so this is roughly covering what Jeremy just said the first half of the module in terms of what he'll be doing practically in the labs, kind of first coursework. For the second coursework, you'll be doing some practical voice user interface design work using a prototyping tool called voice flow. Now, voice flow is going to be free for us to use, but they're going to set us up with a university account. You can go and register for free yourself, but it'll be a limited free account, um, which will not be the account that you will be getting through. Um, so in other words, just wait. Don't, don't sign up yet. There'll be more instructions on signing up to voice flow, uh, in a few weeks time. So don't worry too much about that. Yeah. Um, what it is, is a visual prototyping and testing tool, so it's quite different to the kind of more low level programming you'll be doing the first semester in the first half of the semester. Um, this is so that we can focus on conversational design principles and not get bogged down in coding. At that point, projects can be tested on an Alexa or Google home device. Um, but you don't have to do that. You can just test it through the web page so you don't have to have a device. So as I said. Voice Well, yeah, we'll set that up as a class, as a class account once in a few weeks time. There's a book, which was we're also going to make available that we're going to be using as part of the learning about, uh, conversational design and that is designed voice user interface. McCarthy For. Okay, So a few more things about the module organisation. So we're all quite used to a hybrid approach where things happen in-person and where things happen online. In-person only attend if you feel if you feel well, you know, we're all used to that now. Please make sure that if you do feel unwell, take a test and do not attend. Um, if you, if you are positive, obviously, and generally speaking, if you're on well, you should probably not spread your germs around. Um, and yes, so what we do in-person is we do like texts and labs in the rooms as timetabled. Well, we're actually going to try and get a different room because this is clearly too small for you. But we come from a staff, but we're going to try and we've got a lecture today, obviously Mondays, Thursdays here in this in this room as well. And we're in a 32, four hour labs on Fridays, Friday afternoons. The parties long. Yeah. Um, so what's happening? Remote it online. All content is on moodle as always. Um, lecture recordings will be made available after the lecture. Um, so it's recording right now. So we're recording life and then making those available. If you cannot make it, you can catch up that way with the lectures. We have a team. Any of you have signed up to it already? Please do so. The link is on the movie page, so sign up yourself. There's a code for it. Again. This on the page. Um. This teams that we are using to talk about any questions you have, please don't email me because there's 150 of you. If I get a good 150 times the same question. It's quite inefficient to use email, whereas if it's just on teams, everybody can see the answer or somebody else might be able to answer. Answer it. I'm not, you know, the only person, Jeremy said. We also have a number of teams that are helping us out, so they will be able to answer questions and they can. But if you email me, it's going to take me a while to get to my email. So don't email me unless you absolutely have to. Um, okay. So teams. Yeah, team teams. I talked about that. We also use that for important announcements to make sure you sign up to the team. So what you should do, say it again, head to the mental page of the module. If you can't see the page, you may not be officially enrolled. The page is now visible, so let me know. Jeremy No, and we can argue manually to that because sometimes enrolment, particularly for for MSC students, is delayed because well, because it's university and things get delayed, but we can just add you manually. So if you cannot see it, email me. This is an exception. This is where you're allowed to email me and Jeremy as well, and we can add you manually to the Moodle page. Um, there's a section there called Read this first, so I recommend you read it and it will just give you the same instructions how to sign up to the team. There's a code that you need to input, so the code is on the Moodle page. Okay, sign up. It's easy. This is the timetable. You all have the timetable. So we'll see you on Thursday for the next lecture and Friday. Friday for our first lab. So what we're doing in the lectures, um, we are kind of doing this where we're discussing theory and practice, let's say, Right. So theory is things like critical issues in the research, design, development and deployment of AI driven systems. That's my research area, so I'd like to talk about it. So you're going to have some of that in the lectures. Not all of that is directly, practically relevant to the coursework, but it is going to be relevant to the topic at large and the content. So things like that will also cover things like the basics of computing with natural language, algorithmic bias, topics like that, and conversational design. All of these topics will be assessed by quizzes which count for 30% of your overall mark. Talk about that a little bit more as well. And then the practical side of the module is kind of as, as we already said, roughly split into two halves, the first half being about natural language processing in the second half about voice user interface design. And that that's what the laughs relate to as well. So the first half of the labs roughly will be about natural language processing. That's Jeremy. That's Jeremy said it'll be about practically developing natural language processing chatbot. So this will make use of Python as the main language analytics I could learn and so on. And that will conclude with coursework one, which is 40% of your overall module mark. The second half roughly of the module will be will be about voice user interface prototyping and conversational design, where you'll be using voice flow and a quick call score to. Which is not due until the until after the Christmas break. And. And that will be worth 30% of your mark for his attempts to schedule. We don't have to go through it. Just the first thing to note is probably the first question. First bit of assessment will be probably tentative, but we'll probably be in in week five. So in four weeks from now because we're in week two. So in four weeks from now on the Friday what be how we're doing the quizzes this is important is that we'll be done during the lab hours. So the idea is that you're all there in the lab or you can be at home as well, but there will be a there's a fixed window, a fixed time window, or when you have to take quizzes. We took our time window and the quiz will be you will have 30 or 45 minutes. We haven't quite decided yet from when you start the quiz. Sorry. Yeah, open book. It's open, but you only have 30 or 45 minutes to do it. But you have to do it in that two hour time window. If you're really interested in knowing why that is the case, I can I can give you the answer, but it's pretty boring. So that is happening in four weeks. That's the first quiz, which is worth 10%. And it's going to consist of ten questions. Okay. And it's multiple choice because that's what quizzes on Moodle like. Okay. And then. And then what else? Coursework one will be two a few weeks after that, which will also be the week when we're doing the second quiz. This will be later. Later in November. Okay. And then quiz three will be kind of the penultimate week or so before Christmas. Right. And then then your Christmas break. And then the final course will be after Christmas. Okay, So that's the tentative schedule. And then so just to repeat what you should do next to sign up the team and structure ceremony and attend the next lecture on Thursday. SPENCE Now, do you have any questions, 24 questions on item figure two.

SPEAKER 1
I'm going to preamble a lot of questions that I'm going to get later about the quizzes. The quizzes are not difficult, right? They're not there's no trick question or, you know, do this complicated math calculation in 10 minutes thing. Right. But they do require understanding the classical and that that's really like the lowest bar we can find. Just if you can understand it, course content, you'll be fine. If you don't understand, you'll be in trouble. So yeah, don't stress out about the quizzes. They're fine. You'll be fine. I think that usually the score is quite high.

SPEAKER 0
Yeah. And the quizzes will cover the weeks of content up until the point of the quiz as well, so you'll know which lectures to cover. I just rehearsed, like, just kind of go over the material again in preparation and. And. Yeah, you'll be fine. Any questions? Yeah. Will there be a lot? Yes, there will be a lab on Friday at 4 p.m.. Four till 6 p.m.. The party's not.

SPEAKER 1
You. Don't you think so? Yeah.

UNKNOWN
So I just think you. Oh.

SPEAKER 0
I said, Well, sorry, but even mean as an observer. Okay. Yeah. So unless you already have access, which you may not just email me and I can add you as an observer to move C then you don't wish you're an observer, you can't take any assessments and you can't get credits for the module. Just so everyone knows. Yeah.

SPEAKER 2
I. Yeah. Mm.

SPEAKER 0
Yeah. I just come out after this woman asked me to. Yeah. I can take a note if your name.

SPEAKER 1
Is probably easier to email so we can do a batch, but we're not going to be the only one. And this is your brother list of people directly.

SPEAKER 0
And at once. Yeah. Who else? Who else needs to enrol has not enrolled on the one? Yeah. Okay. Definitely email. Yeah. So it's quite a few. So let's just do it by email sharing my email address. Okay. My email address is my name.

SPEAKER 1
Oh 20.

SPEAKER 0
900. It might be on the first line now. Okay, I'll type it here.

SPEAKER 1
What? Besides. We're going to get some.

SPEAKER 0
Don't email me Facebook and any other questions? Questions, questions.

SPEAKER 1
I'll be sharing.

SPEAKER 0
Okay. See you on Thursday.

SPEAKER 1
With the bigger cuts from.
